{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eefbe327-8323-46a2-bbbd-78a2b455930c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Great Expectations V5 - Main Orchestrator\n",
    "\n",
    "\n",
    "\n",
    "**Steps Overview**:\n",
    "- **Step 1**: Environment Diagnostics & Package Installation\n",
    "- **Step 2**: GX Context Setup & API Discovery  \n",
    "- **Step 3**: SQL Server Connection & Data Loading\n",
    "- **Step 4**: Data Quality Validation Setup\n",
    "- **Step 4.5**: Team Rules Definition Library \n",
    "- **Step 5**: Expectation Validation Execution\n",
    "- **Step 6**: Results Analysis & Reporting\n",
    "- **Step 7**: Data Docs Generation\n",
    "- **Step 8**: Azure OpenAI Integration (Optional)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b194b09-9e2b-4dc6-8df7-ba4b26df0a12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Configuration\n",
    "BASE_PATH = \"/Workspace/Users/prashanth.kumar4@shell.com/Great-expectations-DataQuality-v1\"\n",
    "STEPS = [\n",
    "    \"step1_environment_diagnostics\",\n",
    "    \"step2_gx_context_setup\",\n",
    "    \"step2_5_gx_methods_demo\", \n",
    "    \"step3_sql_connection_data\",\n",
    "    \"step4_validation_setup\",\n",
    "    \"step4_5_rules_definition\",  \n",
    "    \"step5_expectation_validation\",\n",
    "    \"step6_results_analysis\",\n",
    "    \"step7_data_docs\",\n",
    "    \"step8_azure_openai\"\n",
    "]\n",
    "\n",
    "\n",
    "pipeline_status = {}\n",
    "pipeline_results = {}\n",
    "\n",
    "\n",
    "\n",
    "def run_pipeline_step(step_name, step_number, timeout_seconds=600, skip_on_error=False):\n",
    "    \"\"\"\n",
    "    Execute a pipeline step notebook and handle results\n",
    "    \n",
    "    Args:\n",
    "        step_name: Name of the step notebook (without .ipynb)\n",
    "        step_number: Step number for tracking\n",
    "        timeout_seconds: Timeout for notebook execution  \n",
    "        skip_on_error: Whether to continue pipeline if step fails\n",
    "    \"\"\"\n",
    "    print(f\"\\n STEP {step_number}: {step_name}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    step_path = f\"{BASE_PATH}/{step_name}\"\n",
    "    \n",
    "    try:\n",
    "        # Run the step notebook\n",
    "        print(f\"Executing: {step_path}\")\n",
    "        result = dbutils.notebook.run(step_path, timeout_seconds)\n",
    "        \n",
    "        # Parse result (notebooks should return JSON status)\n",
    "        import json\n",
    "        try:\n",
    "            # Try to parse as JSON first\n",
    "            if result and result.strip().startswith('{'):\n",
    "                step_result = json.loads(result)\n",
    "            elif result:\n",
    "                # If not JSON, treat as plain text message\n",
    "                step_result = {\"status\": \"success\", \"message\": f\"Completed: {result}\"}\n",
    "            else:\n",
    "                # No return value - this is normal for most notebooks\n",
    "                step_result = {\"status\": \"success\", \"message\": f\"Step {step_number} executed successfully\"}\n",
    "        except Exception as parse_error:\n",
    "            # Fallback for any parsing issues\n",
    "            step_result = {\"status\": \"success\", \"message\": f\"Completed (output: {str(result)[:50]}...)\"}\n",
    "        \n",
    "        # Update pipeline status\n",
    "        pipeline_status[step_name] = \"SUCCESS\"\n",
    "        pipeline_results[step_name] = step_result\n",
    "        \n",
    "        print(f\"SUCCESS: {step_name}\")\n",
    "        print(f\"Result: {step_result.get('message', 'No message')}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        print(f\"ERROR in {step_name}: {error_msg}\")\n",
    "        \n",
    "        pipeline_status[step_name] = \"FAILED\"\n",
    "        pipeline_results[step_name] = {\"status\": \"error\", \"message\": error_msg}\n",
    "        \n",
    "        if skip_on_error:\n",
    "            print(f\"Continuing pipeline despite error (skip_on_error=True)\")\n",
    "            return False\n",
    "        else:\n",
    "            print(f\"Stopping pipeline due to error\")\n",
    "            raise Exception(f\"Pipeline failed at {step_name}: {error_msg}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a282424-6949-4f59-abc0-f586f8fb89f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n STEP 1: step1_environment_diagnostics\n--------------------------------------------------\nExecuting: /Workspace/Users/prashanth.kumar4@shell.com/Great-expectations-DataQuality-v1/step1_environment_diagnostics\nSUCCESS: step1_environment_diagnostics\nResult: Step 1 executed successfully\n\n STEP 2: step2_gx_context_setup\n--------------------------------------------------\nExecuting: /Workspace/Users/prashanth.kumar4@shell.com/Great-expectations-DataQuality-v1/step2_gx_context_setup\nSUCCESS: step2_gx_context_setup\nResult: No message\n\n STEP 3: step2_5_gx_methods_demo\n--------------------------------------------------\nExecuting: /Workspace/Users/prashanth.kumar4@shell.com/Great-expectations-DataQuality-v1/step2_5_gx_methods_demo\nSUCCESS: step2_5_gx_methods_demo\nResult: No message\n\n STEP 4: step3_sql_connection_data\n--------------------------------------------------\nExecuting: /Workspace/Users/prashanth.kumar4@shell.com/Great-expectations-DataQuality-v1/step3_sql_connection_data\nSUCCESS: step3_sql_connection_data\nResult: No message\n\n STEP 5: step4_validation_setup\n--------------------------------------------------\nExecuting: /Workspace/Users/prashanth.kumar4@shell.com/Great-expectations-DataQuality-v1/step4_validation_setup\nSUCCESS: step4_validation_setup\nResult: No message\n\n STEP 6: step4_5_rules_definition\n--------------------------------------------------\nExecuting: /Workspace/Users/prashanth.kumar4@shell.com/Great-expectations-DataQuality-v1/step4_5_rules_definition\nSUCCESS: step4_5_rules_definition\nResult: No message\n\n STEP 7: step5_expectation_validation\n--------------------------------------------------\nExecuting: /Workspace/Users/prashanth.kumar4@shell.com/Great-expectations-DataQuality-v1/step5_expectation_validation\nSUCCESS: step5_expectation_validation\nResult: No message\n\n STEP 8: step6_results_analysis\n--------------------------------------------------\nExecuting: /Workspace/Users/prashanth.kumar4@shell.com/Great-expectations-DataQuality-v1/step6_results_analysis\nSUCCESS: step6_results_analysis\nResult: Step 8 executed successfully\n\n STEP 9: step7_data_docs\n--------------------------------------------------\nExecuting: /Workspace/Users/prashanth.kumar4@shell.com/Great-expectations-DataQuality-v1/step7_data_docs\nSUCCESS: step7_data_docs\nResult: No message\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# EXECUTE PIPELINE STEPS\n",
    "\n",
    "\n",
    "\n",
    "run_pipeline_step(\"step1_environment_diagnostics\", 1, timeout_seconds=300)\n",
    "run_pipeline_step(\"step2_gx_context_setup\", 2, timeout_seconds=300)\n",
    "run_pipeline_step(\"step2_5_gx_methods_demo\", 3, timeout_seconds=300)\n",
    "run_pipeline_step(\"step3_sql_connection_data\", 4, timeout_seconds=600)\n",
    "run_pipeline_step(\"step4_validation_setup\", 5, timeout_seconds=300)\n",
    "run_pipeline_step(\"step4_5_rules_definition\", 6, timeout_seconds=300)\n",
    "run_pipeline_step(\"step5_expectation_validation\", 7, timeout_seconds=600)\n",
    "run_pipeline_step(\"step6_results_analysis\", 8, timeout_seconds=300)\n",
    "run_pipeline_step(\"step7_data_docs\", 9, timeout_seconds=300, skip_on_error=True)\n",
    "# run_pipeline_step(\"step8_azure_openai\", 10, timeout_seconds=300, skip_on_error=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2df84748-698a-40d1-a675-b1b91d7bce07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# PIPELINE  REPORT\n",
    "\n",
    "total_steps = len(STEPS)\n",
    "successful_steps = sum(1 for status in pipeline_status.values() if status == \"SUCCESS\")\n",
    "failed_steps = sum(1 for status in pipeline_status.values() if status == \"FAILED\")\n",
    "\n",
    "print(f\"SUMMARY:\")\n",
    "print(f\"   Total Steps: {total_steps}\")\n",
    "print(f\"  Successful: {successful_steps}\")\n",
    "print(f\"    Failed: {failed_steps}\")\n",
    "print(f\"    Success Rate: {(successful_steps/total_steps)*100:.1f}%\")\n",
    "\n",
    "# Detailed status\n",
    "print(f\"\\nDETAILED STEP STATUS:\")\n",
    "for i, step in enumerate(STEPS, 1):\n",
    "    status = pipeline_status.get(step, \"NOT_RUN\")\n",
    "    result = pipeline_results.get(step, {})\n",
    "    \n",
    "    status_emoji = \"\" if status == \"SUCCESS\" else \"\" if status == \"FAILED\" else \"\"\n",
    "    print(f\"   {status_emoji} Step {i}: {step} - {status}\")\n",
    "    \n",
    "    if \"message\" in result:\n",
    "        message = result[\"message\"][:100] + \"...\" if len(result[\"message\"]) > 100 else result[\"message\"]\n",
    "        print(f\"       {message}\")\n",
    "\n",
    "# Critical path analysis\n",
    "critical_failures = [step for step in STEPS[:6] if pipeline_status.get(step) == \"FAILED\"]\n",
    "if critical_failures:\n",
    "    print(f\"\\n  CRITICAL FAILURES (Steps 1-6):\")\n",
    "    for step in critical_failures:\n",
    "        print(f\"    {step}\")\n",
    "    print(f\"    Recommendation: Fix these before proceeding\")\n",
    "else:\n",
    "    print(f\"\\n CORE PIPELINE STATUS: ALL CRITICAL STEPS SUCCESSFUL\")\n",
    "\n",
    "# Generate summary for downstream use\n",
    "pipeline_summary = {\n",
    "    \"total_steps\": total_steps,\n",
    "    \"successful_steps\": successful_steps, \n",
    "    \"failed_steps\": failed_steps,\n",
    "    \"success_rate\": (successful_steps/total_steps)*100,\n",
    "    \"critical_failures\": critical_failures,\n",
    "    \"status\": \"SUCCESS\" if not critical_failures else \"PARTIAL_SUCCESS\",\n",
    "    \"ready_for_production\": successful_steps >= 6  # Steps 1-6 are core\n",
    "}\n",
    "\n",
    "print(f\"\\n Pipeline ready for production: {pipeline_summary['ready_for_production']}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Return summary for parent workflows\n",
    "import json\n",
    "dbutils.notebook.exit(json.dumps(pipeline_summary))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "GX_Main_Orchestrator_v5",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}